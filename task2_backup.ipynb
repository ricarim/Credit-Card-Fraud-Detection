{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Predictive Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from adjustText import adjust_text\n",
    "from geopy.distance import geodesic\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training and test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'CategoricalDtype' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[117], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvariables/index_mapping.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     17\u001b[0m     index_mapping \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m---> 19\u001b[0m \u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'CategoricalDtype' object is not callable"
     ]
    }
   ],
   "source": [
    "with open(\"variables/X_train.pkl\", \"rb\") as f:\n",
    "    X_train = pickle.load(f)\n",
    "\n",
    "with open(\"variables/y_train.pkl\", \"rb\") as f:\n",
    "    y_train = pickle.load(f)\n",
    "\n",
    "with open(\"variables/X_test.pkl\", \"rb\") as f:\n",
    "    X_test = pickle.load(f)\n",
    "\n",
    "with open(\"variables/y_test.pkl\", \"rb\") as f:\n",
    "    y_test = pickle.load(f)\n",
    "\n",
    "with open(\"variables/kaggle_data.pkl\", \"rb\") as f:\n",
    "    kaggle_data = pickle.load(f)\n",
    "\n",
    "with open(\"variables/index_mapping.pkl\", \"rb\") as f:\n",
    "    index_mapping = pickle.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Imbalance - SMOTE and model pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampling_rates = [0.5,0.6,0.7]  # Fraction of majority class\n",
    "undersampling_rates = [0.8,0.9] # Fraction of total dataset for the majority class\n",
    "\n",
    "\n",
    "\n",
    "def model_pipeline(model, submission_file, use_random_search=False, param_grid=None, n_iter=10):\n",
    "    results = []\n",
    "    best_model = None\n",
    "    best_auc = 0 \n",
    "    best_config = None \n",
    "\n",
    "    for oversampling_rate in oversampling_rates:\n",
    "        for undersampling_rate in undersampling_rates:\n",
    "            print(f\"\\nTesting Oversampling={oversampling_rate}, Undersampling={undersampling_rate}\")\n",
    "            \n",
    "            # Define SMOTE and undersampler\n",
    "            smote = SMOTE(sampling_strategy=oversampling_rate, random_state=42)\n",
    "            undersampler = RandomUnderSampler(sampling_strategy=undersampling_rate, random_state=42)\n",
    "            \n",
    "            # Create pipeline\n",
    "            pipeline = Pipeline(steps=[\n",
    "                ('smote', smote),\n",
    "                ('undersampler', undersampler),\n",
    "                ('model', model)\n",
    "            ])\n",
    "            \n",
    "            if use_random_search:\n",
    "                search = RandomizedSearchCV(\n",
    "                    estimator=pipeline,\n",
    "                    param_distributions=param_grid,  # Prefix for model params\n",
    "                    n_iter=n_iter,\n",
    "                    scoring='roc_auc',\n",
    "                    cv=5,\n",
    "                    n_jobs=-1,\n",
    "                    random_state=42 \n",
    "                )\n",
    "                # Train with hyperparameter tuning\n",
    "                search.fit(X_train, y_train)\n",
    "                best_pipeline = search.best_estimator_\n",
    "                best_params = search.best_params_\n",
    "                print(f\"Best Parameters for this iteration: {best_params}\")\n",
    "            else:\n",
    "                # Train pipeline without hyperparameter search\n",
    "                pipeline.fit(X_train, y_train)\n",
    "                best_pipeline = pipeline\n",
    "                best_params = \"Default parameters\"\n",
    "\n",
    "\n",
    "            \n",
    "            # Predict on the test set\n",
    "            y_pred = best_pipeline.predict(X_test)\n",
    "            y_pred_proba = best_pipeline.predict_proba(X_test)[:, 1]  # Get probabilities for AUC\n",
    "\n",
    "            \n",
    "            # Evaluate model\n",
    "            print(\"Classification Report:\")\n",
    "            report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "            \n",
    "            \n",
    "            # Confusion matrix\n",
    "            print(\"Confusion Matrix:\")\n",
    "            print(confusion_matrix(y_test, y_pred))\n",
    "            \n",
    "            # Calculate AUC\n",
    "            auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "           \n",
    "\n",
    "            # Store results\n",
    "            results.append({\n",
    "                'oversampling_rate': oversampling_rate,\n",
    "                'undersampling_rate': undersampling_rate,\n",
    "                'precision': report['1']['precision'],\n",
    "                'recall': report['1']['recall'],\n",
    "                'f1_score': report['1']['f1-score'],\n",
    "                'auc': auc_score\n",
    "            })\n",
    "2\n",
    "            # Check if current model is the best\n",
    "            if auc_score > best_auc:\n",
    "                best_auc = auc_score\n",
    "                best_model = best_pipeline\n",
    "                best_config = {\n",
    "                    'oversampling_rate': oversampling_rate,\n",
    "                    'undersampling_rate': undersampling_rate\n",
    "                }\n",
    "\n",
    "    # Print best configuration\n",
    "    print(\"\\nBest Configuration:\")\n",
    "    print(f\"Oversampling Rate: {best_config['oversampling_rate']}\")\n",
    "    print(f\"Undersampling Rate: {best_config['undersampling_rate']}\")\n",
    "    print(f\"Best AUC: {best_auc:.4f}\")\n",
    "\n",
    "    # Predict probabilities for Kaggle submission\n",
    "    test_probs = best_model.predict_proba(kaggle_data)[:, 1]  # Probabilities for class 1 (fraud)\n",
    "\n",
    "    # Create submission DataFrame\n",
    "    submission = pd.DataFrame({\n",
    "        'index': index_mapping,\n",
    "        'is_fraud': test_probs\n",
    "    })\n",
    "\n",
    "    # Save to CSV\n",
    "    submission_file_name = f\"{submission_file}.csv\"\n",
    "    submission.to_csv(f\"submission/{submission_file_name}\", index=False)\n",
    "    print(f\"Submission file created: '{submission_file_name}'\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Oversampling=0.5, Undersampling=0.8\n",
      "Classification Report:\n",
      "Confusion Matrix:\n",
      "[[5882    4]\n",
      " [ 114    0]]\n",
      "\n",
      "Testing Oversampling=0.5, Undersampling=1.0\n",
      "Classification Report:\n",
      "Confusion Matrix:\n",
      "[[5880    6]\n",
      " [ 114    0]]\n",
      "\n",
      "Testing Oversampling=0.7, Undersampling=0.8\n",
      "Classification Report:\n",
      "Confusion Matrix:\n",
      "[[5885    1]\n",
      " [ 114    0]]\n",
      "\n",
      "Testing Oversampling=0.7, Undersampling=1.0\n",
      "Classification Report:\n",
      "Confusion Matrix:\n",
      "[[5882    4]\n",
      " [ 114    0]]\n",
      "\n",
      "Best Configuration:\n",
      "Oversampling Rate: 0.5\n",
      "Undersampling Rate: 1.0\n",
      "Best AUC: 0.4655\n",
      "Submission file created: 'submission_random_forest.csv'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'oversampling_rate': 0.5,\n",
       "  'undersampling_rate': 0.8,\n",
       "  'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'auc': np.float64(0.43127462727494914)},\n",
       " {'oversampling_rate': 0.5,\n",
       "  'undersampling_rate': 1.0,\n",
       "  'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'auc': np.float64(0.4655434244803309)},\n",
       " {'oversampling_rate': 0.7,\n",
       "  'undersampling_rate': 0.8,\n",
       "  'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'auc': np.float64(0.43850781813521233)},\n",
       " {'oversampling_rate': 0.7,\n",
       "  'undersampling_rate': 1.0,\n",
       "  'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'auc': np.float64(0.43363005287598877)}]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a Random Forest Classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "model_pipeline(rf,\"submission_random_forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Search - Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Oversampling=0.5, Undersampling=0.8\n",
      "Best Parameters for this iteration: {'model__n_estimators': 100, 'model__min_samples_split': 5, 'model__min_samples_leaf': 4, 'model__max_depth': 10}\n",
      "Classification Report:\n",
      "Confusion Matrix:\n",
      "[[5886    0]\n",
      " [ 114    0]]\n",
      "\n",
      "Testing Oversampling=0.5, Undersampling=1.0\n",
      "Best Parameters for this iteration: {'model__n_estimators': 100, 'model__min_samples_split': 5, 'model__min_samples_leaf': 4, 'model__max_depth': 10}\n",
      "Classification Report:\n",
      "Confusion Matrix:\n",
      "[[5886    0]\n",
      " [ 114    0]]\n",
      "\n",
      "Testing Oversampling=0.7, Undersampling=0.8\n",
      "Best Parameters for this iteration: {'model__n_estimators': 100, 'model__min_samples_split': 5, 'model__min_samples_leaf': 4, 'model__max_depth': 10}\n",
      "Classification Report:\n",
      "Confusion Matrix:\n",
      "[[5886    0]\n",
      " [ 114    0]]\n",
      "\n",
      "Testing Oversampling=0.7, Undersampling=1.0\n",
      "Best Parameters for this iteration: {'model__n_estimators': 100, 'model__min_samples_split': 5, 'model__min_samples_leaf': 4, 'model__max_depth': 10}\n",
      "Classification Report:\n",
      "Confusion Matrix:\n",
      "[[5886    0]\n",
      " [ 114    0]]\n",
      "\n",
      "Best Configuration:\n",
      "Oversampling Rate: 0.5\n",
      "Undersampling Rate: 1.0\n",
      "Best AUC: 0.4935\n",
      "Submission file created: 'submission_random_search_random_forest.csv'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'oversampling_rate': 0.5,\n",
       "  'undersampling_rate': 0.8,\n",
       "  'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'auc': np.float64(0.47421624908346294)},\n",
       " {'oversampling_rate': 0.5,\n",
       "  'undersampling_rate': 1.0,\n",
       "  'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'auc': np.float64(0.4935238836132124)},\n",
       " {'oversampling_rate': 0.7,\n",
       "  'undersampling_rate': 0.8,\n",
       "  'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'auc': np.float64(0.47737271312838675)},\n",
       " {'oversampling_rate': 0.7,\n",
       "  'undersampling_rate': 1.0,\n",
       "  'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'auc': np.float64(0.4841342227468093)}]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_distributions = {\n",
    "        'model__n_estimators': [100, 200, 500,1000],      \n",
    "        'model__max_depth': [None, 10, 20, 30],     \n",
    "        'model__min_samples_split': [2, 5, 10],         \n",
    "        'model__min_samples_leaf': [1, 2, 4, 5],                           \n",
    "    }\n",
    "\n",
    "model_pipeline(rf,\"submission_random_search_random_forest\",True,param_distributions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Score on Kaggle:** 0.52296"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Oversampling=0.5, Undersampling=0.8\n",
      "Classification Report:\n",
      "Confusion Matrix:\n",
      "[[5841   45]\n",
      " [ 114    0]]\n",
      "\n",
      "Testing Oversampling=0.5, Undersampling=1.0\n",
      "Classification Report:\n",
      "Confusion Matrix:\n",
      "[[5840   46]\n",
      " [ 114    0]]\n",
      "\n",
      "Testing Oversampling=0.7, Undersampling=0.8\n",
      "Classification Report:\n",
      "Confusion Matrix:\n",
      "[[5864   22]\n",
      " [ 114    0]]\n",
      "\n",
      "Testing Oversampling=0.7, Undersampling=1.0\n",
      "Classification Report:\n",
      "Confusion Matrix:\n",
      "[[5851   35]\n",
      " [ 114    0]]\n",
      "\n",
      "Best Configuration:\n",
      "Oversampling Rate: 0.5\n",
      "Undersampling Rate: 0.8\n",
      "Best AUC: 0.4529\n",
      "Submission file created: 'submission_xgboost.csv'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'oversampling_rate': 0.5,\n",
       "  'undersampling_rate': 0.8,\n",
       "  'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'auc': np.float64(0.452863172201656)},\n",
       " {'oversampling_rate': 0.5,\n",
       "  'undersampling_rate': 1.0,\n",
       "  'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'auc': np.float64(0.43907264338215557)},\n",
       " {'oversampling_rate': 0.7,\n",
       "  'undersampling_rate': 0.8,\n",
       "  'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'auc': np.float64(0.4474265429118157)},\n",
       " {'oversampling_rate': 0.7,\n",
       "  'undersampling_rate': 1.0,\n",
       "  'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'auc': np.float64(0.4478035898444719)}]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "xgb = XGBClassifier(n_estimators=500, max_depth=5, learning_rate=0.1, random_state=42)\n",
    "\n",
    "\n",
    "model_pipeline(xgb,\"submission_xgboost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Score on Kaggle:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Search - XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Oversampling=0.5, Undersampling=0.8\n",
      "Best Parameters for this iteration: {'model__subsample': 1.0, 'model__reg_lambda': 1, 'model__reg_alpha': 0, 'model__n_estimators': 100, 'model__min_child_weight': 5, 'model__max_depth': 7, 'model__learning_rate': 0.1, 'model__colsample_bytree': 0.8}\n",
      "Classification Report:\n",
      "Confusion Matrix:\n",
      "[[5886    0]\n",
      " [ 114    0]]\n",
      "\n",
      "Testing Oversampling=0.5, Undersampling=1.0\n",
      "Best Parameters for this iteration: {'model__subsample': 1.0, 'model__reg_lambda': 1, 'model__reg_alpha': 0, 'model__n_estimators': 100, 'model__min_child_weight': 5, 'model__max_depth': 7, 'model__learning_rate': 0.1, 'model__colsample_bytree': 0.8}\n",
      "Classification Report:\n",
      "Confusion Matrix:\n",
      "[[5886    0]\n",
      " [ 114    0]]\n",
      "\n",
      "Testing Oversampling=0.7, Undersampling=0.8\n",
      "Best Parameters for this iteration: {'model__subsample': 1.0, 'model__reg_lambda': 1, 'model__reg_alpha': 0, 'model__n_estimators': 100, 'model__min_child_weight': 5, 'model__max_depth': 7, 'model__learning_rate': 0.1, 'model__colsample_bytree': 0.8}\n",
      "Classification Report:\n",
      "Confusion Matrix:\n",
      "[[5886    0]\n",
      " [ 114    0]]\n",
      "\n",
      "Testing Oversampling=0.7, Undersampling=1.0\n",
      "Best Parameters for this iteration: {'model__subsample': 1.0, 'model__reg_lambda': 1, 'model__reg_alpha': 0, 'model__n_estimators': 100, 'model__min_child_weight': 5, 'model__max_depth': 7, 'model__learning_rate': 0.1, 'model__colsample_bytree': 0.8}\n",
      "Classification Report:\n",
      "Confusion Matrix:\n",
      "[[5886    0]\n",
      " [ 114    0]]\n",
      "\n",
      "Best Configuration:\n",
      "Oversampling Rate: 0.7\n",
      "Undersampling Rate: 0.8\n",
      "Best AUC: 0.4484\n",
      "Submission file created: 'submission_random_search_xgboost.csv'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'oversampling_rate': 0.5,\n",
       "  'undersampling_rate': 0.8,\n",
       "  'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'auc': np.float64(0.44771715220773656)},\n",
       " {'oversampling_rate': 0.5,\n",
       "  'undersampling_rate': 1.0,\n",
       "  'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'auc': np.float64(0.4407209196964549)},\n",
       " {'oversampling_rate': 0.7,\n",
       "  'undersampling_rate': 0.8,\n",
       "  'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'auc': np.float64(0.44839896632508897)},\n",
       " {'oversampling_rate': 0.7,\n",
       "  'undersampling_rate': 1.0,\n",
       "  'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'auc': np.float64(0.4454444384832281)}]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier(n_estimators=500, max_depth=5, learning_rate=0.1, random_state=42)\n",
    "\n",
    "param_distributions = {\n",
    "        'model__n_estimators': [100, 200, 300, 500, 1000],\n",
    "        'model__learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "        'model__max_depth': [3, 5, 7, 10],\n",
    "        'model__subsample': [0.6, 0.8, 1.0],\n",
    "        'model__colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'model__reg_alpha': [0, 0.1, 1, 10],\n",
    "        'model__reg_lambda': [1, 10, 50],\n",
    "        'model__min_child_weight': [1, 3, 5, 7]\n",
    "    }\n",
    "\n",
    "\n",
    "model_pipeline(xgb,\"submission_random_search_xgboost\",True, param_distributions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Score on Kaggle:** 0.52380"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Oversampling=0.5, Undersampling=0.8\n",
      "Best Parameters for this iteration: {'model__min_samples_split': 20, 'model__min_samples_leaf': 1, 'model__max_leaf_nodes': 100, 'model__max_features': 4, 'model__max_depth': 50}\n",
      "Classification Report:\n",
      "Confusion Matrix:\n",
      "[[5118  768]\n",
      " [ 102   12]]\n",
      "\n",
      "Testing Oversampling=0.5, Undersampling=1.0\n",
      "Best Parameters for this iteration: {'model__min_samples_split': 20, 'model__min_samples_leaf': 1, 'model__max_leaf_nodes': 100, 'model__max_features': 4, 'model__max_depth': 50}\n",
      "Classification Report:\n",
      "Confusion Matrix:\n",
      "[[4791 1095]\n",
      " [ 100   14]]\n",
      "\n",
      "Testing Oversampling=0.7, Undersampling=0.8\n",
      "Best Parameters for this iteration: {'model__min_samples_split': 10, 'model__min_samples_leaf': 4, 'model__max_leaf_nodes': None, 'model__max_features': 7, 'model__max_depth': 10}\n",
      "Classification Report:\n",
      "Confusion Matrix:\n",
      "[[5850   36]\n",
      " [ 112    2]]\n",
      "\n",
      "Testing Oversampling=0.7, Undersampling=1.0\n",
      "Best Parameters for this iteration: {'model__min_samples_split': 10, 'model__min_samples_leaf': 5, 'model__max_leaf_nodes': None, 'model__max_features': 1, 'model__max_depth': 20}\n",
      "Classification Report:\n",
      "Confusion Matrix:\n",
      "[[5213  673]\n",
      " [  99   15]]\n",
      "\n",
      "Best Configuration:\n",
      "Oversampling Rate: 0.7\n",
      "Undersampling Rate: 1.0\n",
      "Best AUC: 0.5068\n",
      "Submission file created: 'submission_decision_tree.csv'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'oversampling_rate': 0.5,\n",
       "  'undersampling_rate': 0.8,\n",
       "  'precision': 0.015384615384615385,\n",
       "  'recall': 0.10526315789473684,\n",
       "  'f1_score': 0.026845637583892617,\n",
       "  'auc': np.float64(0.4946654565397524)},\n",
       " {'oversampling_rate': 0.5,\n",
       "  'undersampling_rate': 1.0,\n",
       "  'precision': 0.012623985572587917,\n",
       "  'recall': 0.12280701754385964,\n",
       "  'f1_score': 0.022894521668029435,\n",
       "  'auc': np.float64(0.4907832144070677)},\n",
       " {'oversampling_rate': 0.7,\n",
       "  'undersampling_rate': 0.8,\n",
       "  'precision': 0.05263157894736842,\n",
       "  'recall': 0.017543859649122806,\n",
       "  'f1_score': 0.02631578947368421,\n",
       "  'auc': np.float64(0.4855552276886576)},\n",
       " {'oversampling_rate': 0.7,\n",
       "  'undersampling_rate': 1.0,\n",
       "  'precision': 0.02180232558139535,\n",
       "  'recall': 0.13157894736842105,\n",
       "  'f1_score': 0.03740648379052369,\n",
       "  'auc': np.float64(0.5068322990623008)}]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state = 42)\n",
    "\n",
    "parameter_grid = {\n",
    "    'model__max_depth': [5, 10, 20, 30, 40, 50],\n",
    "    'model__min_samples_split': [2, 5, 10, 20],  \n",
    "    'model__min_samples_leaf': [1, 2, 4, 5],   \n",
    "    'model__max_leaf_nodes': [None, 10, 20, 50, 100],\n",
    "    'model__max_features': [1, 2, 3, 4, 5, 6, 7, 8,]\n",
    "}\n",
    "\n",
    "model_pipeline(dt,\"submission_decision_tree\",True, parameter_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks - Multi-Layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Oversampling=0.5, Undersampling=0.8\n",
      "Classification Report:\n",
      "Confusion Matrix:\n",
      "[[   0 5886]\n",
      " [   0  114]]\n",
      "\n",
      "Testing Oversampling=0.5, Undersampling=1.0\n",
      "Classification Report:\n",
      "Confusion Matrix:\n",
      "[[   0 5886]\n",
      " [   0  114]]\n",
      "\n",
      "Testing Oversampling=0.7, Undersampling=0.8\n",
      "Classification Report:\n",
      "Confusion Matrix:\n",
      "[[5886    0]\n",
      " [ 114    0]]\n",
      "\n",
      "Testing Oversampling=0.7, Undersampling=1.0\n",
      "Classification Report:\n",
      "Confusion Matrix:\n",
      "[[5886    0]\n",
      " [ 114    0]]\n",
      "\n",
      "Best Configuration:\n",
      "Oversampling Rate: 0.5\n",
      "Undersampling Rate: 0.8\n",
      "Best AUC: 0.5000\n",
      "Submission file created: 'submission_mlp.csv'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'oversampling_rate': 0.5,\n",
       "  'undersampling_rate': 0.8,\n",
       "  'precision': 0.019,\n",
       "  'recall': 1.0,\n",
       "  'f1_score': 0.03729146221786065,\n",
       "  'auc': np.float64(0.5)},\n",
       " {'oversampling_rate': 0.5,\n",
       "  'undersampling_rate': 1.0,\n",
       "  'precision': 0.019,\n",
       "  'recall': 1.0,\n",
       "  'f1_score': 0.03729146221786065,\n",
       "  'auc': np.float64(0.5)},\n",
       " {'oversampling_rate': 0.7,\n",
       "  'undersampling_rate': 0.8,\n",
       "  'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'auc': np.float64(0.5)},\n",
       " {'oversampling_rate': 0.7,\n",
       "  'undersampling_rate': 1.0,\n",
       "  'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'auc': np.float64(0.5)}]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "model_pipeline(mlp,\"submission_mlp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Search - Neural Networks (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Oversampling=0.5, Undersampling=0.8\n",
      "Best Parameters for this iteration: {'model__solver': 'adam', 'model__learning_rate': 'adaptive', 'model__hidden_layer_sizes': (100, 50), 'model__alpha': 0.0001, 'model__activation': 'relu'}\n",
      "Classification Report:\n",
      "Confusion Matrix:\n",
      "[[5886    0]\n",
      " [ 114    0]]\n",
      "\n",
      "Testing Oversampling=0.5, Undersampling=1.0\n",
      "Best Parameters for this iteration: {'model__solver': 'adam', 'model__learning_rate': 'adaptive', 'model__hidden_layer_sizes': (100, 50), 'model__alpha': 0.0001, 'model__activation': 'relu'}\n",
      "Classification Report:\n",
      "Confusion Matrix:\n",
      "[[   0 5886]\n",
      " [   0  114]]\n",
      "\n",
      "Testing Oversampling=0.7, Undersampling=0.8\n",
      "Best Parameters for this iteration: {'model__solver': 'adam', 'model__learning_rate': 'constant', 'model__hidden_layer_sizes': (50,), 'model__alpha': 0.0001, 'model__activation': 'relu'}\n",
      "Classification Report:\n",
      "Confusion Matrix:\n",
      "[[ 365 5521]\n",
      " [   7  107]]\n",
      "\n",
      "Testing Oversampling=0.7, Undersampling=1.0\n",
      "Best Parameters for this iteration: {'model__solver': 'adam', 'model__learning_rate': 'constant', 'model__hidden_layer_sizes': (50,), 'model__alpha': 0.0001, 'model__activation': 'relu'}\n",
      "Classification Report:\n",
      "Confusion Matrix:\n",
      "[[5886    0]\n",
      " [ 114    0]]\n",
      "\n",
      "Best Configuration:\n",
      "Oversampling Rate: 0.7\n",
      "Undersampling Rate: 0.8\n",
      "Best AUC: 0.5003\n",
      "Submission file created: 'submission_random_search_mlp.csv'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'oversampling_rate': 0.5,\n",
       "  'undersampling_rate': 0.8,\n",
       "  'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'auc': np.float64(0.5)},\n",
       " {'oversampling_rate': 0.5,\n",
       "  'undersampling_rate': 1.0,\n",
       "  'precision': 0.019,\n",
       "  'recall': 1.0,\n",
       "  'f1_score': 0.03729146221786065,\n",
       "  'auc': np.float64(0.5)},\n",
       " {'oversampling_rate': 0.7,\n",
       "  'undersampling_rate': 0.8,\n",
       "  'precision': 0.019012082444918265,\n",
       "  'recall': 0.9385964912280702,\n",
       "  'f1_score': 0.03726924416579589,\n",
       "  'auc': np.float64(0.5003040220326556)},\n",
       " {'oversampling_rate': 0.7,\n",
       "  'undersampling_rate': 1.0,\n",
       "  'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'auc': np.float64(0.5)}]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_grid = {\n",
    "    'model__hidden_layer_sizes': [(50,), (100,), (100, 50), (150, 100)],\n",
    "    'model__activation': ['relu', 'tanh'],\n",
    "    'model__solver': ['adam', 'sgd'],\n",
    "    'model__alpha': [0.0001, 0.001, 0.01],\n",
    "    'model__learning_rate': ['constant', 'adaptive']\n",
    "}\n",
    "\n",
    "model_pipeline(mlp,\"submission_random_search_mlp\",True,parameter_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[111], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43maa\u001b[49m\n\u001b[1;32m      2\u001b[0m svm \u001b[38;5;241m=\u001b[39m SVC(kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrbf\u001b[39m\u001b[38;5;124m'\u001b[39m, probability\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#svm.fit(X_train, y_train)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'aa' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "svm = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "\n",
    "\n",
    "model_pipeline(svm,\"submission_svm\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
